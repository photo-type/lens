{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"hamza\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv from opencv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test.JPG',0)\n",
    "img2 = img.copy()\n",
    "template = cv2.imread('template.png',0)\n",
    "w, h = template.shape[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "\n",
    "for meth in methods:\n",
    "    img = img2.copy()\n",
    "    method = eval(meth)\n",
    "\n",
    "    # Apply template Matching\n",
    "    res = cv2.matchTemplate(img,template,method)\n",
    "    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "\n",
    "    # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "    if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "        top_left = min_loc\n",
    "    else:\n",
    "        top_left = max_loc\n",
    "    bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "\n",
    "    cv2.rectangle(img,top_left, bottom_right, 255, 2)\n",
    "\n",
    "    plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
    "    plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "    plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    "    plt.suptitle(meth)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "im = Image.open(\"test.JPG\")\n",
    "\n",
    "text = pytesseract.image_to_string(im, lang = 'eng')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "im = Image.open(\"sample1.jpg\")\n",
    "\n",
    "text = pytesseract.image_to_string(im, lang = 'eng')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "im = Image.open(\"test.JPG\")\n",
    "\n",
    "text = pytesseract.image_to_string(im, lang = 'eng')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"asdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mat src = Imgcodecs.imread(\"test.JPG\");\n",
    "                Mat bt = new Mat();\n",
    "                Imgproc.cvtColor(src, bt, Imgproc.COLOR_BGR2GRAY);\n",
    "                Imgproc.threshold(bt, bt, 0, 255, Imgproc.THRESH_BINARY);\n",
    "                Imgcodecs.imwrite(\"output.png\",bt);\n",
    "\n",
    "                int xmin = bt.cols();\n",
    "                int ymin = bt.rows();\n",
    "                int xmax=0;                \n",
    "                int ymax=0;\n",
    "\n",
    "                double[] pixel = new double[0];\n",
    "                for (int x = 0; x < bt.cols(); x++) {\n",
    "                    for (int y = 0; y < bt.rows(); y++) {\n",
    "\n",
    "                        pixel = bt.get(y, x);\n",
    "\n",
    "                        if( pixel[0] == 0)\n",
    "                        {\n",
    "                            if( x < xmin )\n",
    "                            {\n",
    "                                xmin = x;\n",
    "                            }\n",
    "\n",
    "                            if( y < ymin )\n",
    "                            {\n",
    "                                ymin = y;\n",
    "                            }\n",
    "\n",
    "                            if( x > xmax )\n",
    "                            {\n",
    "                                xmax = x;\n",
    "                            }\n",
    "\n",
    "                            if( y > ymax )\n",
    "                            {\n",
    "                                ymax = y;\n",
    "                            }\n",
    "                        }\n",
    "\n",
    "                    }\n",
    "                }\n",
    "                //xmin = xmin - 3;  // you can try to uncomment these lines\n",
    "                //ymin = ymin - 3;\n",
    "                //xmax = xmax + 3;\n",
    "                //ymax = ymax + 3;\n",
    "\n",
    "                Rect roi = new Rect(xmin, ymin, xmax-xmin, ymax-ymin);\n",
    "                Mat cr = new Mat(src, roi);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('test.JPG')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "_,thresh = cv2.threshold(gray,1,255,cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnt = contours[0]\n",
    "x,y,w,h = cv2.boundingRect(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = img[y:y+h,x:x+w]\n",
    "cv2.imwrite('output.png',crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread('test.JPG', 0)\n",
    "img = cv2.medianBlur(img, 5)\n",
    "thresh =     cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "cv2.THRESH_BINARY,11,2)\n",
    "plt.imshow(thresh)\n",
    "\n",
    "image, contours, hierarchy =   cv2.findContours(thresh.copy(),cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cv2.drawContours(image, contours, -1, (0,255,0), 3)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv2.imread('test.JPG', 0)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to detect the boundary of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7837335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def threshold(im, method):\n",
    "    # make it grayscale\n",
    "    im_gray = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    if method == 'fixed':\n",
    "        threshed_im = cv2.threshold(im_gray, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    elif method == 'mean':\n",
    "        threshed_im = cv2.adaptiveThreshold(im_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 5, 7)\n",
    "\n",
    "    elif method == 'gaussian':\n",
    "        threshed_im = cv2.adaptiveThreshold(im_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 5, 12)\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return threshed_im\n",
    "\n",
    "\n",
    "image = cv2.imread('screen.jpg')\n",
    "\n",
    "# threshold it\n",
    "thresh = threshold(image, 'mean')\n",
    "height,width,channels = image.shape\n",
    "image_area = width*height\n",
    "largest_area=0;\n",
    "largest_contour_index=0\n",
    "bounding_rect=0\n",
    "print(image_area)\n",
    "# find contours\n",
    "_, contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts=[]\n",
    "for i in contours:\n",
    "    cnt=i\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if (area>largest_area and area < (image_area - 20000)):\n",
    "        largest_area=area\n",
    "        largest_contour_index=i\n",
    "        bounding_rect=cnt\n",
    "cv2.drawContours(image, [bounding_rect], -1, (0, 255, 0), 10)\n",
    "cv2.imwrite('output.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread('test_page.JPG',0)\n",
    "edges = cv2.Canny(img,200,300)\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To remove noise and backgrounds from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 77  95  96]\n",
      "  [ 86 104 105]\n",
      "  [ 91 106 108]\n",
      "  ...\n",
      "  [ 43  93 113]\n",
      "  [ 44  91 113]\n",
      "  [ 43  90 112]]\n",
      "\n",
      " [[ 78  96  97]\n",
      "  [ 87 105 106]\n",
      "  [ 92 107 109]\n",
      "  ...\n",
      "  [ 44  94 114]\n",
      "  [ 45  92 114]\n",
      "  [ 45  92 114]]\n",
      "\n",
      " [[ 79  97  98]\n",
      "  [ 89 107 108]\n",
      "  [ 94 109 111]\n",
      "  ...\n",
      "  [ 45  95 115]\n",
      "  [ 47  94 116]\n",
      "  [ 46  93 115]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 92  99  94]\n",
      "  [ 94 101  96]\n",
      "  [ 95 102  97]\n",
      "  ...\n",
      "  [100 112 100]\n",
      "  [ 99 111  99]\n",
      "  [ 98 110  98]]\n",
      "\n",
      " [[ 90  97  92]\n",
      "  [ 92  99  94]\n",
      "  [ 93 100  95]\n",
      "  ...\n",
      "  [100 112 100]\n",
      "  [ 99 111  99]\n",
      "  [ 98 110  98]]\n",
      "\n",
      " [[ 89  96  91]\n",
      "  [ 90  97  92]\n",
      "  [ 92  99  94]\n",
      "  ...\n",
      "  [100 112 100]\n",
      "  [ 99 111  99]\n",
      "  [ 98 110  98]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('Image.jpeg')\n",
    "print(image)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "# check to see if we should apply thresholding to preprocess the\n",
    "# image\n",
    "gray = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    " \n",
    "gray = cv2.medianBlur(gray, 3)\n",
    "\n",
    "cv2.imwrite(\"new.jpg\", gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crop the boundary, screen name and actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12192768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def threshold(im, method):\n",
    "    # make it grayscale\n",
    "    im_gray = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    if method == 'fixed':\n",
    "        threshed_im = cv2.threshold(im_gray, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    elif method == 'mean':\n",
    "        threshed_im = cv2.adaptiveThreshold(im_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 5, 7)\n",
    "\n",
    "    elif method == 'gaussian':\n",
    "        threshed_im = cv2.adaptiveThreshold(im_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 5, 12)\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return threshed_im\n",
    "\n",
    "\n",
    "image = cv2.imread('gray2.jpg')\n",
    "\n",
    "# threshold it\n",
    "thresh = threshold(image, 'mean')\n",
    "height,width,channels = image.shape\n",
    "image_area = width*height\n",
    "largest_area=0;\n",
    "largest_contour_index=0\n",
    "bounding_rect=0\n",
    "print(image_area)\n",
    "# find contours\n",
    "_, contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts=[]\n",
    "for i in contours:\n",
    "    cnt=i\n",
    "    area = cv2.contourArea(cnt)\n",
    "    if (area>largest_area and area < (image_area - 20000)):\n",
    "        largest_area=area\n",
    "        largest_contour_index=i\n",
    "        bounding_rect=cnt\n",
    "\n",
    "\n",
    "# img = image\n",
    "# mask = np.ones_like(img) # Create mask where white is what we want, black otherwise\n",
    "# cv2.drawContours(mask, [bounding_rect], -1, 255, -1) # Draw filled contour in mask\n",
    "# out = np.ones_like(img) # Extract out the object and place into output image\n",
    "# out[mask == 255] = img[mask == 255]\n",
    "\n",
    "# # Now crop\n",
    "# (x, y, z) = np.where(mask == 255)\n",
    "# (topx, topy) = (np.min(x), np.min(y))\n",
    "# (bottomx, bottomy) = (np.max(x), np.max(y))\n",
    "# out = out[topx:bottomx+1, topy:bottomy+1]\n",
    "x,y,w,h = cv2.boundingRect(bounding_rect)\n",
    "\n",
    "screenName = image[0:y,0:width]\n",
    "actions = image[y+h:height, 0:width]\n",
    "out = image[y:y+h,x:x+w]\n",
    "\n",
    "# Show the output image\n",
    "cv2.imwrite('output.jpg', out)\n",
    "cv2.imwrite('actions.jpg', actions)\n",
    "cv2.imwrite('screen_name.jpg', screenName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to detect the inner boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7837335\n",
      "(1166, 397)\n",
      "(1232, 463)\n",
      "(1172, 403)\n",
      "(1222, 226)\n",
      "(1301, 303)\n",
      "(1228, 232)\n",
      "(1367, 243)\n",
      "(1441, 321)\n",
      "(1373, 249)\n",
      "(1238, 469)\n",
      "(1309, 310)\n",
      "(1448, 328)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "def threshold(im, method):\n",
    "    # make it grayscale\n",
    "    im_gray = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    if method == 'fixed':\n",
    "        threshed_im = cv2.threshold(im_gray, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    elif method == 'mean':\n",
    "        threshed_im = cv2.adaptiveThreshold(im_gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 5, 7)\n",
    "\n",
    "    elif method == 'gaussian':\n",
    "        threshed_im = cv2.adaptiveThreshold(im_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 5, 12)\n",
    "\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return threshed_im\n",
    "\n",
    "\n",
    "image = cv2.imread('screen.jpg')\n",
    "\n",
    "# threshold it\n",
    "thresh = threshold(image, 'mean')\n",
    "height,width,channels = image.shape\n",
    "image_area = width*height\n",
    "largest_area=image_area;\n",
    "largest_contour_index=0\n",
    "bounding_rect=0\n",
    "print(image_area)\n",
    "# find contours\n",
    "_, contours, hierarchy = cv2.findContours(thresh.copy(), cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts=[]\n",
    "for i in contours:\n",
    "    cnt=i\n",
    "    area = cv2.contourArea(cnt)\n",
    "    (x,y,w,h) = cv2.boundingRect(cnt)\n",
    "    if ((w > 1000 and w < 2000) and (h > 50 and h < 1000)):\n",
    "        print(w,h)\n",
    "        cnts.append(cnt)\n",
    "    \n",
    "cv2.drawContours(image, cnts, -1, (0, 255, 0), 10)\n",
    "cv2.imwrite('output.jpg', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # OCR with AWS Rekognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B OK\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import cv2\n",
    "import simplejson as json\n",
    "\n",
    "img = cv2.imread('ocr_test_gray.jpg')\n",
    "\n",
    "jpg_as_text = cv2.imencode('.jpg', img)[1].tostring()\n",
    "session = boto3.Session(profile_name='phototype')\n",
    "client = session.client('rekognition', region_name='ap-southeast-2')\n",
    "response = client.detect_text(Image={\n",
    "    'Bytes': jpg_as_text\n",
    "})\n",
    "print(response['TextDetections'][0]['DetectedText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'HTTPHeaders': {'connection': 'keep-alive',\n",
       "   'content-length': '3445',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Tue, 01 May 2018 15:54:09 GMT',\n",
       "   'x-amzn-requestid': 'dde11835-4d57-11e8-a349-453e9c57cd02'},\n",
       "  'HTTPStatusCode': 200,\n",
       "  'RequestId': 'dde11835-4d57-11e8-a349-453e9c57cd02',\n",
       "  'RetryAttempts': 0},\n",
       " u'TextDetections': [{u'Confidence': 90.95767211914062,\n",
       "   u'DetectedText': u'B OK',\n",
       "   u'Geometry': {u'BoundingBox': {u'Height': 0.13369081914424896,\n",
       "     u'Left': 0.11943987011909485,\n",
       "     u'Top': 0.036412328481674194,\n",
       "     u'Width': 0.5978915691375732},\n",
       "    u'Polygon': [{u'X': 0.11943987011909485, u'Y': 0.036412328481674194},\n",
       "     {u'X': 0.7173314094543457, u'Y': 0.035086389631032944},\n",
       "     {u'X': 0.7178584933280945, u'Y': 0.1687772125005722},\n",
       "     {u'X': 0.11996695399284363, u'Y': 0.17010314762592316}]},\n",
       "   u'Id': 0,\n",
       "   u'Type': u'LINE'},\n",
       "  {u'Confidence': 88.51775360107422,\n",
       "   u'DetectedText': u'C:D',\n",
       "   u'Geometry': {u'BoundingBox': {u'Height': 0.13040316104888916,\n",
       "     u'Left': 0.12019377946853638,\n",
       "     u'Top': 0.22331060469150543,\n",
       "     u'Width': 0.5066178441047668},\n",
       "    u'Polygon': [{u'X': 0.12019377946853638, u'Y': 0.22331060469150543},\n",
       "     {u'X': 0.6268116235733032, u'Y': 0.19565217196941376},\n",
       "     {u'X': 0.6394680738449097, u'Y': 0.3260553181171417},\n",
       "     {u'X': 0.13285024464130402, u'Y': 0.3537137806415558}]},\n",
       "   u'Id': 1,\n",
       "   u'Type': u'LINE'},\n",
       "  {u'Confidence': 89.9108657836914,\n",
       "   u'DetectedText': u'LOGIN: D',\n",
       "   u'Geometry': {u'BoundingBox': {u'Height': 0.12111397087574005,\n",
       "     u'Left': 0.09943515062332153,\n",
       "     u'Top': 0.3750618100166321,\n",
       "     u'Width': 0.8294622898101807},\n",
       "    u'Polygon': [{u'X': 0.09943515062332153, u'Y': 0.3750618100166321},\n",
       "     {u'X': 0.9288974404335022, u'Y': 0.3335603177547455},\n",
       "     {u'X': 0.9396705031394958, u'Y': 0.45467430353164673},\n",
       "     {u'X': 0.11020819842815399, u'Y': 0.49617576599121094}]},\n",
       "   u'Id': 2,\n",
       "   u'Type': u'LINE'},\n",
       "  {u'Confidence': 92.81588745117188,\n",
       "   u'DetectedText': u'LOGIN:',\n",
       "   u'Geometry': {u'BoundingBox': {u'Height': 0.1254529058933258,\n",
       "     u'Left': 0.10507246106863022,\n",
       "     u'Top': 0.36141303181648254,\n",
       "     u'Width': 0.6364734172821045},\n",
       "    u'Polygon': [{u'X': 0.10299800336360931, u'Y': 0.38097938895225525},\n",
       "     {u'X': 0.7336792349815369, u'Y': 0.35968488454818726},\n",
       "     {u'X': 0.7399807572364807, u'Y': 0.46466562151908875},\n",
       "     {u'X': 0.10929952561855316, u'Y': 0.4859601557254791}]},\n",
       "   u'Id': 6,\n",
       "   u'ParentId': 2,\n",
       "   u'Type': u'WORD'},\n",
       "  {u'Confidence': 87.43893432617188,\n",
       "   u'DetectedText': u'OK',\n",
       "   u'Geometry': {u'BoundingBox': {u'Height': 0.1096014529466629,\n",
       "     u'Left': 0.4559178650379181,\n",
       "     u'Top': 0.04891304299235344,\n",
       "     u'Width': 0.2614734172821045},\n",
       "    u'Polygon': [{u'X': 0.456307977437973, u'Y': 0.048911936581134796},\n",
       "     {u'X': 0.717391312122345, u'Y': 0.05027176812291145},\n",
       "     {u'X': 0.7163974046707153, u'Y': 0.15760983526706696},\n",
       "     {u'X': 0.4553140699863434, u'Y': 0.15625}]},\n",
       "   u'Id': 4,\n",
       "   u'ParentId': 0,\n",
       "   u'Type': u'WORD'},\n",
       "  {u'Confidence': 88.51775360107422,\n",
       "   u'DetectedText': u'C:D',\n",
       "   u'Geometry': {u'BoundingBox': {u'Height': 0.15534420311450958,\n",
       "     u'Left': 0.11835748702287674,\n",
       "     u'Top': 0.19610507786273956,\n",
       "     u'Width': 0.522946834564209},\n",
       "    u'Polygon': [{u'X': 0.12019377946853638, u'Y': 0.22331060469150543},\n",
       "     {u'X': 0.6268116235733032, u'Y': 0.19565217196941376},\n",
       "     {u'X': 0.6394680738449097, u'Y': 0.3260553181171417},\n",
       "     {u'X': 0.13285024464130402, u'Y': 0.3537137806415558}]},\n",
       "   u'Id': 5,\n",
       "   u'ParentId': 1,\n",
       "   u'Type': u'WORD'},\n",
       "  {u'Confidence': 94.47640991210938,\n",
       "   u'DetectedText': u'B',\n",
       "   u'Geometry': {u'BoundingBox': {u'Height': 0.13316039741039276,\n",
       "     u'Left': 0.12289416790008545,\n",
       "     u'Top': 0.035997625440359116,\n",
       "     u'Width': 0.21931661665439606},\n",
       "    u'Polygon': [{u'X': 0.11948951333761215, u'Y': 0.04900483414530754},\n",
       "     {u'X': 0.32993313670158386, u'Y': 0.03594551980495453},\n",
       "     {u'X': 0.3432897925376892, u'Y': 0.15701526403427124},\n",
       "     {u'X': 0.1328461766242981, u'Y': 0.17007458209991455}]},\n",
       "   u'Id': 3,\n",
       "   u'ParentId': 0,\n",
       "   u'Type': u'WORD'},\n",
       "  {u'Confidence': 87.00584411621094,\n",
       "   u'DetectedText': u'D',\n",
       "   u'Geometry': {u'BoundingBox': {u'Height': 0.11618649214506149,\n",
       "     u'Left': 0.7934813499450684,\n",
       "     u'Top': 0.33565232157707214,\n",
       "     u'Width': 0.14254121482372284},\n",
       "    u'Polygon': [{u'X': 0.7965125441551208, u'Y': 0.3401840925216675},\n",
       "     {u'X': 0.9293464422225952, u'Y': 0.33860787749290466},\n",
       "     {u'X': 0.9316458106040955, u'Y': 0.4476073086261749},\n",
       "     {u'X': 0.7988119125366211, u'Y': 0.44918355345726013}]},\n",
       "   u'Id': 7,\n",
       "   u'ParentId': 2,\n",
       "   u'Type': u'WORD'}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "here\n",
      "[u'B OK', u'C:D', u'LOGIN: D']\n"
     ]
    }
   ],
   "source": [
    "detectedActions = [];\n",
    "for text in response['TextDetections']:\n",
    "    if (text['Type'] == 'LINE' and text['Confidence'] > 80):\n",
    "        detectedActions.append(text['DetectedText'])\n",
    "print(detectedActions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got it\n"
     ]
    }
   ],
   "source": [
    "s='Line'\n",
    "if (s == 'Line' and s[0] == 'L'):\n",
    "    print('got it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
